---
# Default values for edc-dataplane.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# -- Specifies how many replicas of a deployed pod shall be created during the deployment
# Note: If horizontal pod autoscaling is enabled this setting has no effect
replicaCount: 1

image:
  # -- Which derivate of the edc data-plane to use.
  # One of: [ghcr.io/catenax-ng/product-edc/edc-dataplane-hashicorp-vault, ghcr.io/catenax-ng/product-edc/edc-dataplane-azure-vault]
  repository: ghcr.io/catenax-ng/product-edc/edc-dataplane-hashicorp-vault
  # -- [Kubernetes image pull policy](https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy) to use
  pullPolicy: IfNotPresent
  # -- Overrides the image tag whose default is the chart appVersion
  tag: ""

imagePullSecret:
  # -- Image pull secret to create to [obtain the container image from private registries](https://kubernetes.io/docs/concepts/containers/images/#using-a-private-registry)
  # Note: This value needs to adhere to the [(base64 encoded) .dockerconfigjson format](https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/#registry-secret-existing-credentials).
  # Furthermore, if 'imagePullSecret.dockerconfigjson' is defined, it takes precedence over 'imagePullSecrets'.
  dockerconfigjson: ""

# -- Existing image pull secret to use to [obtain the container image from private registries](https://kubernetes.io/docs/concepts/containers/images/#using-a-private-registry)
imagePullSecrets: []

# -- Overrides the charts name
nameOverride: ""

# -- Overrides the releases full name
fullnameOverride: ""

serviceAccount:
  # -- Specifies whether a [service account](https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/) should be created per release
  create: true
  # -- [Annotations](https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/) to add to the service account
  annotations: {}
  # -- The name of the service account to use. If not set and create is true, a name is generated using the release's fullname template
  name: ""

# -- Whether to [automount kubernetes API credentials](https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#use-the-default-service-account-to-access-the-api-server) into the pod
automountServiceAccountToken: false

# -- [Annotations](https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/) added to deployed [pods](https://kubernetes.io/docs/concepts/workloads/pods/)
podAnnotations: {}

# The [pod security context](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod) defines privilege and access control settings for a Pod within the deployment
podSecurityContext:
  seccompProfile:
    # -- Restrict a Container's Syscalls with seccomp
    type: RuntimeDefault
  # -- Runs all processes within a pod with a special uid
  runAsUser: 10001
  # -- Processes within a pod will belong to this guid
  runAsGroup: 10001
  # -- The owner for volumes and any files created within volumes will belong to this guid
  fsGroup: 10001

# The [container security context](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container) defines privilege and access control settings for a Container within a pod
securityContext:
  capabilities:
    # -- Specifies which capabilities to drop to reduce syscall attack surface
    drop:
      - ALL
    # -- Specifies which capabilities to add to issue specialized syscalls
    add: []
  # -- Whether the root filesystem is mounted in read-only mode
  readOnlyRootFilesystem: true
  # -- Controls [Privilege Escalation](https://kubernetes.io/docs/concepts/security/pod-security-policy/#privilege-escalation) enabling setuid binaries changing the effective user ID
  allowPrivilegeEscalation: false
  # -- Requires the container to run without root privileges
  runAsNonRoot: true
  # -- The container's process will run with the specified uid
  runAsUser: 10001

livenessProbe:
  # -- Whether to enable kubernetes [liveness-probe](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)
  enabled: true

readinessProbe:
  # -- Whether to enable kubernetes readiness-probes
  enabled: true

startupProbe:
  # -- Whether to enable kubernetes startup-probes
  enabled: true
  # -- Minimum consecutive failures for the probe to be considered failed after having succeeded
  failureThreshold: 12
  # -- Number of seconds after the container has started before liveness probes are initiated.
  initialDelaySeconds: 10

## EDC endpoints exposed by the data-plane
edc:
  endpoints:
    ## Default api exposing health checks etc
    default:
      # -- The network port, which the "default" api is going to be exposed by the container, pod and service
      port: "8080"
      # -- The path mapping the "default" api is going to be exposed by
      path: /api
    ## Public endpoint for data transfer
    public:
      # -- The network port, which the "public" api is going to be exposed by the container, pod and service
      port: "8185"
      # -- The path mapping the "public" api is going to be exposed by
      path: /api/public
    ## Control API
    control:
      # -- The network port, which the "control" api is going to be exposed by the container, pod and service
      port: "9999"
      # -- The path mapping the "control" api is going to be exposed by
      path: /api/dataplane/control
    ## Prometheus endpoint
    metrics:
      # -- The network port, which the prometheus metrics are going to be exposed by the container, pod and service
      port: "9090"
      # -- The path mapping the prometheus metrics are going to be exposed at
      path: /metrics

service:
  # -- [Service type](https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types) to expose the running application on a set of Pods as a network service.
  type: ClusterIP

## Ingress declaration to expose the network service.
ingresses:
  ## Public / Internet facing Ingress
  - enabled: true
    # -- The hostname to be used to precisely map incoming traffic onto the underlying network service
    hostname: "edc-dataplane.local"
    # -- Additional ingress annotations to add
    annotations: {}
    # -- EDC endpoints exposed by this ingress resource
    endpoints:
      - public
    # -- Defines the [ingress class](https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-class)  to use
    className: ""
    # -- TLS [tls class](https://kubernetes.io/docs/concepts/services-networking/ingress/#tls) applied to the ingress resource
    tls:
      # -- Enables TLS on the ingress resource
      enabled: false
      # -- If present overwrites the default secret name
      secretName: ""
    ## Adds [cert-manager](https://cert-manager.io/docs/) annotations to the ingress resource
    certManager:
      # -- If preset enables certificate generation via cert-manager namespace scoped issuer
      issuer: ""
      # -- If preset enables certificate generation via cert-manager cluster-wide issuer
      clusterIssuer: ""

# -- [Resource management](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/) applied to the deployed pod
resources:
  {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  # -- Enables [horizontal pod autoscaling](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)
  enabled: false
  # -- Minimal replicas if resource consumption falls below resource threshholds
  minReplicas: 1
  # -- Maximum replicas if resource consumption exceeds resource threshholds
  maxReplicas: 100
  # -- targetAverageUtilization of cpu provided to a pod
  targetCPUUtilizationPercentage: 80
  # -- targetAverageUtilization of memory provided to a pod
  targetMemoryUtilizationPercentage: 80

# -- [Node-Selector](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector) to constrain the Pod to nodes with specific labels.
nodeSelector: {}

# -- [Tolerations](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/) are applied to Pods to schedule onto nodes with matching taints.
tolerations: []

# -- [Affinity](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity) constrains which nodes the Pod can be scheduled on based on node labels.
affinity: {}

# -- Container environment variables e.g. for configuring [JAVA_TOOL_OPTIONS](https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/envvars002.html)
# Ex.:
#   JAVA_TOOL_OPTIONS: >
#     -Dhttp.proxyHost=proxy -Dhttp.proxyPort=80 -Dhttp.nonProxyHosts="localhost|127.*|[::1]" -Dhttps.proxyHost=proxy -Dhttps.proxyPort=443
env: {}

# -- [Kubernetes Secret Resource](https://kubernetes.io/docs/concepts/configuration/secret/) name to load environment variables from
envSecretName:

logging:
  # -- EDC logging.properties configuring the [java.util.logging subsystem](https://docs.oracle.com/javase/7/docs/technotes/guides/logging/overview.html#a1.8)
  properties: |-
    .level=INFO
    org.eclipse.dataspaceconnector.level=ALL
    handlers=java.util.logging.ConsoleHandler
    java.util.logging.ConsoleHandler.formatter=java.util.logging.SimpleFormatter
    java.util.logging.ConsoleHandler.level=ALL
    java.util.logging.SimpleFormatter.format=[%1$tY-%1$tm-%1$td %1$tH:%1$tM:%1$tS] [%4$-7s] %5$s%6$s%n

opentelemetry:
  # -- opentelemetry.properties configuring the [opentelemetry agent](https://opentelemetry.io/docs/instrumentation/java/automatic/agent-config/)
  properties: |-
    otel.javaagent.enabled=true
    otel.javaagent.debug=false

configuration:
  # -- EDC configuration.properties configuring aspects of the [eclipse-dataspaceconnector](https://github.com/eclipse-dataspaceconnector/DataSpaceConnector)
  properties: |-
    # edc.atomikos.checkpoint.interval=
    # edc.atomikos.directory=
    # edc.atomikos.logging=
    # edc.atomikos.threaded2pc=
    # edc.atomikos.timeout=
    # edc.aws.access.key=
    # edc.aws.provision.retry.retries.max=
    # edc.aws.provision.role.duration.session.max=
    # edc.aws.secret.access.key=
    # edc.blobstore.endpoint=
    # edc.dataplane.token.validation.endpoint=
    # edc.core.retry.backoff.max=
    # edc.core.retry.backoff.min=
    # edc.core.retry.retries.max=
    # edc.core.system.health.check.liveness-period=
    # edc.core.system.health.check.readiness-period=
    # edc.core.system.health.check.startup-period=
    # edc.core.system.health.check.threadpool-size=
    # edc.dataplane.queue.capacity=
    # edc.dataplane.wait=
    # edc.dataplane.workers=
    # edc.datasource.asset.name="default"
    # edc.datasource.contractdefinition.name="default"
    # edc.datasource.contractnegotiation.name="default"
    # edc.datasource.policy.name="default"
    # edc.datasource.transferprocess.name="default"
    # edc.datasource.default.pool.maxIdleConnections=
    # edc.datasource.default.pool.maxTotalConnections=
    # edc.datasource.default.pool.minIdleConnections=
    # edc.datasource.default.pool.testConnectionOnBorrow=
    # edc.datasource.default.pool.testConnectionOnCreate=
    # edc.datasource.default.pool.testConnectionOnReturn=
    # edc.datasource.default.pool.testConnectionWhileIdle=
    # edc.datasource.default.pool.testQuery=
    # edc.datasource.default.url=
    # edc.datasource.default.user=
    # edc.datasource.default.password=
    # edc.dpf.selector.url=
    # edc.events.topic.endpoint=
    # edc.events.topic.name=
    # edc.fs.config=
    # edc.hostname=
    # edc.identity.did.url=
    # edc.ids.catalog.id=
    # edc.ids.curator=
    # edc.ids.description=
    # edc.ids.endpoint=
    # edc.ids.endpoint.audience=
    # edc.ids.id=
    # edc.ids.maintainer=
    # edc.ids.security.profile=
    # edc.ids.title=
    # edc.ids.validation.referringconnector=
    # edc.ion.crawler.did-type=
    # edc.ion.crawler.interval-minutes=
    # edc.ion.crawler.ion.url=
    # edc.metrics.enabled=
    # edc.metrics.executor.enabled=
    # edc.metrics.jersey.enabled=
    # edc.metrics.jetty.enabled=
    # edc.metrics.okhttp.enabled=
    # edc.metrics.system.enabled=
    # edc.negotiation.consumer.state-machine.batch-size=
    # edc.negotiation.provider.state-machine.batch-size=
    # edc.oauth.client.id=
    # edc.oauth.private.key.alias=
    # edc.oauth.provider.jwks.refresh=
    # edc.oauth.provider.jwks.url=
    # edc.oauth.public.key.alias=
    # edc.oauth.token.url=
    # edc.oauth.validation.nbf.leeway=
    # edc.receiver.http.auth-code=
    # edc.receiver.http.auth-key=
    # edc.receiver.http.endpoint=
    # edc.transfer.functions.check.endpoint=
    # edc.transfer.functions.enabled.protocols=
    # edc.transfer.functions.transfer.endpoint=
    # edc.transfer-process-store.database.name=
    # edc.transfer.state-machine.batch-size=
    # edc.vault=
    # edc.vault.certificate=
    # edc.vault.clientid=
    # edc.vault.clientsecret=
    # edc.vault.name=
    # edc.vault.tenantid=
    # edc.vault.hashicorp.url=
    # edc.vault.hashicorp.token=
    # edc.vault.hashicorp.timeout.seconds=
    # edc.webdid.doh.url=
    # edc.web.rest.cors.enabled=
    # edc.web.rest.cors.headers=
    # edc.web.rest.cors.methods=
    # edc.web.rest.cors.origins=
