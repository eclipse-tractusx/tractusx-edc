#
#  Copyright (c) 2023 ZF Friedrichshafen AG
#  Copyright (c) 2023 Mercedes-Benz Tech Innovation GmbH
#  Copyright (c) 2023 Bayerische Motoren Werke Aktiengesellschaft (BMW AG)
#  Copyright (c) 2021, 2023 Contributors to the Eclipse Foundation
#
#  See the NOTICE file(s) distributed with this work for additional
#  information regarding copyright ownership.
#
#  This program and the accompanying materials are made available under the
#  terms of the Apache License, Version 2.0 which is available at
#  https://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#  License for the specific language governing permissions and limitations
#  under the License.
#
#  SPDX-License-Identifier: Apache-2.0
#

---
name: "Business Tests"

on:
  pull_request:
    paths-ignore:
      - 'docs/**'
      - '**/*.md'
    branches:
      - releases
      - release/**
      - main
      - previews/**
  workflow_dispatch:

concurrency:
  # cancel only running jobs on pull requests
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  business-test:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      ##############
      ### Set-Up ###
      ##############
      - uses: actions/checkout@v3.3.0
      - uses: ./.github/actions/setup-java
      - name: Cache ContainerD Image Layers
        uses: actions/cache@v3
        with:
          path: /var/lib/containerd/io.containerd.snapshotter.v1.overlayfs
          key: ${{ runner.os }}-io.containerd.snapshotter.v1.overlayfs
      - name: Set-Up Kubectl
        uses: azure/setup-kubectl@v3.2
      - name: Helm Set-Up
        uses: azure/setup-helm@v3.5
        with:
          version: v3.8.1
      - name: Create k8s Kind Cluster configuration (kind.config.yaml)
        run: |-
          export MAVEN_REPOSITORY=${{ github.workspace }}/.m2/repository
          cat << EOF > kind.config.yaml
          ---
          kind: Cluster
          apiVersion: kind.x-k8s.io/v1alpha4
          nodes:
          - role: control-plane
            extraMounts:
              - hostPath: ${PWD}
                containerPath: /srv/tractusx-edc
              - hostPath: ${MAVEN_REPOSITORY}
                containerPath: /srv/m2-repository
              - hostPath: /var/lib/containerd/io.containerd.snapshotter.v1.overlayfs
                containerPath: /var/lib/containerd/io.containerd.snapshotter.v1.overlayfs
          EOF
      - name: Create k8s Kind Cluster
        uses: helm/kind-action@v1.5.0
        with:
          config: kind.config.yaml

      ##############################################
      ### Build and load recent images into KinD ###
      ##############################################
      - name: Build edc-controlplane-postgresql-hashicorp-vault
        run: |-
          ./gradlew :edc-controlplane:edc-controlplane-postgresql-hashicorp-vault:dockerize
        env:
          GITHUB_PACKAGE_USERNAME: ${{ github.actor }}
          GITHUB_PACKAGE_PASSWORD: ${{ secrets.GITHUB_TOKEN }}
      - name: Build edc-dataplane-hashicorp-vault
        run: |-
          ./gradlew :edc-dataplane:edc-dataplane-hashicorp-vault:dockerize
        env:
          GITHUB_PACKAGE_USERNAME: ${{ github.actor }}
          GITHUB_PACKAGE_PASSWORD: ${{ secrets.GITHUB_TOKEN }}
      - name: Load images into KinD
        run: |-
          docker tag edc-controlplane-postgresql-hashicorp-vault:latest edc-controlplane-postgresql-hashicorp-vault:business-test
          docker tag edc-dataplane-hashicorp-vault:latest edc-dataplane-hashicorp-vault:business-test
          kind get clusters | xargs -n1 kind load docker-image edc-controlplane-postgresql-hashicorp-vault:business-test edc-dataplane-hashicorp-vault:business-test --name

      ############################################
      ### Prepare And Install Test Environment ###
      ############################################
      - name: Define test environment variables
        run: |-
          # Define endpoints
          echo "SOKRATES_DATA_MANAGEMENT_API_AUTH_KEY=password" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_DATA_MANAGEMENT_URL=http://sokrates-controlplane:8081/management" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_IDS_URL=http://sokrates-controlplane:8084/api/v1/ids" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_DATA_PLANE_URL=http://sokrates-dataplane:8081/api/public/" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_DATABASE_URL=jdbc:postgresql://plato-postgresql:5432/edc" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_DATABASE_USER=user" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_DATABASE_PASSWORD=password" | tee -a ${GITHUB_ENV}
          echo "PLATO_DATA_MANAGEMENT_API_AUTH_KEY=password" | tee -a ${GITHUB_ENV}
          echo "PLATO_DATA_MANAGEMENT_URL=http://plato-controlplane:8081/management" | tee -a ${GITHUB_ENV}
          echo "PLATO_IDS_URL=http://plato-controlplane:8084/api/v1/ids" | tee -a ${GITHUB_ENV}
          echo "PLATO_DATA_PLANE_URL=http://plato-dataplane:8081/api/public/" | tee -a ${GITHUB_ENV}
          echo "PLATO_DATABASE_URL=jdbc:postgresql://plato-postgresql:5432/edc" | tee -a ${GITHUB_ENV}
          echo "PLATO_DATABASE_USER=user" | tee -a ${GITHUB_ENV}
          echo "PLATO_DATABASE_PASSWORD=password" | tee -a ${GITHUB_ENV}
          echo "EDC_AWS_ENDPOINT_OVERRIDE=http://minio:9000" | tee -a ${GITHUB_ENV}
          echo "PLATO_AWS_SECRET_ACCESS_KEY=platoqwerty123" | tee -a ${GITHUB_ENV}
          echo "PLATO_AWS_ACCESS_KEY_ID=platoqwerty123" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_AWS_SECRET_ACCESS_KEY=sokratesqwerty123" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_AWS_ACCESS_KEY_ID=sokratesqwerty123" | tee -a ${GITHUB_ENV}
      - name: Install infrastructure components via Helm
        uses: nick-fields/retry@v2
        with:
          timeout_minutes: 10
          max_attempts: 3
          retry_on: error
          command: |-
            # Update helm dependencies
            helm dependency update edc-tests/cucumber/src/main/resources/deployment/helm/supporting-infrastructure
            
            # Install the all-in-one supporting infrastructure environment (daps, vault, pgsql, minio)
            helm install infrastructure edc-tests/cucumber/src/main/resources/deployment/helm/supporting-infrastructure \
              --wait-for-jobs --timeout=120s
            
            # GH pipelines constrained by cpu, so give helm some time to register all resources \w k8s
            sleep 5s
            
            # Wait for supporting infrastructure to become ready (control-/data-plane, backend service)
            kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=idsdaps --timeout=120s || ( kubectl logs -l app.kubernetes.io/name=idsdaps --tail 500 && exit 1 )
            kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=vault --timeout=120s || ( kubectl logs -l app.kubernetes.io/name=vault --tail 500 && exit 1 )
            kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=sokrates-postgresql --timeout=120s || ( kubectl logs -l app.kubernetes.io/name=sokrates-postgresql --tail 500 && exit 1 )
            kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=plato-postgresql --timeout=120s || ( kubectl logs -l app.kubernetes.io/name=plato-postgresql --tail 500 && exit 1 )
            kubectl wait --for=condition=ready pod -l app=minio --timeout=120s || ( kubectl logs -l app=minio --tail 500 && exit 1 )
            
            # Install Plato
            helm install plato charts/tractusx-connector  \
              --set fullnameOverride=plato \
              --set controlplane.service.type=NodePort \
              --set controlplane.endpoints.management.authKey=password \
              --set controlplane.image.tag=business-test \
              --set controlplane.image.pullPolicy=Never \
              --set controlplane.image.repository=docker.io/library/edc-controlplane-postgresql-hashicorp-vault \
              --set dataplane.image.tag=business-test \
              --set dataplane.image.pullPolicy=Never \
              --set dataplane.image.repository=docker.io/library/edc-dataplane-hashicorp-vault \
              --set controlplane.debug.enabled=true \
              --set controlplane.suspendOnStart=false \
              --set controlplane.businesspartnervalidation.log.agreement.validation=true \
              --set postgresql.enabled=true \
              --set postgresql.username=user \
              --set postgresql.password=password \
              --set postgresql.jdbcUrl=jdbc:postgresql://plato-postgresql:5432/edc \
              --set vault.hashicorp.enabled=true \
              --set vault.hashicorp.url=http://vault:8200 \
              --set vault.hashicorp.token=root \
              --set vault.secretNames.transferProxyTokenSignerPublicKey=plato/daps/my-plato-daps-crt \
              --set vault.secretNames.transferProxyTokenSignerPrivateKey=plato/daps/my-plato-daps-key \
              --set vault.secretNames.transferProxyTokenEncryptionAesKey=plato/data-encryption-aes-keys \
              --set vault.secretNames.dapsPrivateKey=plato/daps/my-plato-daps-key \
              --set vault.secretNames.dapsPublicKey=plato/daps/my-plato-daps-crt \
              --set daps.url=http://ids-daps:4567 \
              --set daps.clientId=99:83:A7:17:86:FF:98:93:CE:A0:DD:A1:F1:36:FA:F6:0F:75:0A:23:keyid:99:83:A7:17:86:FF:98:93:CE:A0:DD:A1:F1:36:FA:F6:0F:75:0A:23 \
              --set dataplane.aws.endpointOverride=http://minio:9000 \
              --set dataplane.aws.secretAccessKey=platoqwerty123 \
              --set dataplane.aws.accessKeyId=platoqwerty123 \
              --set backendService.httpProxyTokenReceiverUrl=http://backend:8080 \
              --wait-for-jobs --timeout=120s
            
            # Install Sokrates
            helm install sokrates charts/tractusx-connector  \
              --set fullnameOverride=sokrates \
              --set controlplane.service.type=NodePort \
              --set controlplane.endpoints.management.authKey=password \
              --set controlplane.image.tag=business-test \
              --set controlplane.image.pullPolicy=Never \
              --set controlplane.image.repository=docker.io/library/edc-controlplane-postgresql-hashicorp-vault \
              --set dataplane.image.tag=business-test \
              --set dataplane.image.pullPolicy=Never \
              --set dataplane.image.repository=docker.io/library/edc-dataplane-hashicorp-vault \
              --set controlplane.debug.enabled=true \
              --set controlplane.suspendOnStart=false \
              --set controlplane.businesspartnervalidation.log.agreement.validation=true \
              --set postgresql.enabled=true \
              --set postgresql.username=user \
              --set postgresql.password=password \
              --set postgresql.jdbcUrl=jdbc:postgresql://sokrates-postgresql:5432/edc \
              --set vault.hashicorp.enabled=true \
              --set vault.hashicorp.url=http://vault:8200 \
              --set vault.hashicorp.token=root \
              --set vault.secretNames.transferProxyTokenSignerPublicKey=sokrates/daps/my-sokrates-daps-crt \
              --set vault.secretNames.transferProxyTokenSignerPrivateKey=sokrates/daps/my-sokrates-daps-key \
              --set vault.secretNames.transferProxyTokenEncryptionAesKey=sokrates/data-encryption-aes-keys \
              --set vault.secretNames.dapsPrivateKey=sokrates/daps/my-sokrates-daps-key \
              --set vault.secretNames.dapsPublicKey=sokrates/daps/my-sokrates-daps-crt \
              --set daps.url=http://ids-daps:4567 \
              --set daps.clientId=E7:07:2D:74:56:66:31:F0:7B:10:EA:B6:03:06:4C:23:7F:ED:A6:65:keyid:E7:07:2D:74:56:66:31:F0:7B:10:EA:B6:03:06:4C:23:7F:ED:A6:65 \
              --set dataplane.aws.endpointOverride=http://minio:9000 \
              --set dataplane.aws.secretAccessKey=sokratesqwerty123 \
              --set dataplane.aws.accessKeyId=sokratesqwerty123 \
              --set backendService.httpProxyTokenReceiverUrl=http://backend:8080 \
              --wait-for-jobs --timeout=120s
            
            # GH pipelines constrained by cpu, so give helm some time to register all resources \w k8s
            sleep 5s
            
            # Wait for Control-/DataPlane and backend-service to become ready
            kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=sokrates-controlplane --timeout=600s || ( kubectl logs -l app.kubernetes.io/instance=sokrates-controlplane --tail 500 && exit 1 )
            kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=sokrates-dataplane --timeout=600s || ( kubectl logs -l app.kubernetes.io/instance=sokrates-dataplane --tail 500 && exit 1 )
            kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=plato-controlplane --timeout=600s || ( kubectl logs -l app.kubernetes.io/instance=plato-controlplane --tail 500 && exit 1 )
            kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=plato-dataplane --timeout=600s || ( kubectl logs -l app.kubernetes.io/instance=plato-dataplane --tail 500 && exit 1 )

      ##############################################
      ### Run Business Tests inside kind cluster ###
      ##############################################
      - name: Run Business Tests
        continue-on-error: true
        run: |-
          cat << EOF >> pod.json
          {
            "apiVersion": "v1",
            "kind": "Pod",
            "spec": {
              "containers": [
                {
                  "args": [
                    "-c",
                    "cd /tractusx-edc && ./gradlew edc-tests:cucumber:test -Dcucumber=true"
                  ],
                  "command": [
                    "/bin/sh"
                  ],
          EOF

          # Ugly hack to get env vars passed into the k8s-run - if '--overrides' defined '--env' is ignored :(
          cat << EOF >> pod.json
                  "env": [
                    {"name": "SOKRATES_DATA_MANAGEMENT_API_AUTH_KEY", "value": "${SOKRATES_DATA_MANAGEMENT_API_AUTH_KEY}"},
                    {"name": "PLATO_DATA_MANAGEMENT_API_AUTH_KEY", "value": "${PLATO_DATA_MANAGEMENT_API_AUTH_KEY}"},
                    {"name": "SOKRATES_DATA_MANAGEMENT_URL", "value": "${SOKRATES_DATA_MANAGEMENT_URL}"},
                    {"name": "SOKRATES_IDS_URL", "value": "${SOKRATES_IDS_URL}"},
                    {"name": "SOKRATES_DATA_PLANE_URL", "value": "${SOKRATES_DATA_PLANE_URL}"},
                    {"name": "SOKRATES_BACKEND_SERVICE_BACKEND_API_URL", "value": "http://backend:8081" },
                    {"name": "SOKRATES_DATABASE_URL", "value": "${SOKRATES_DATABASE_URL}"},
                    {"name": "SOKRATES_DATABASE_USER", "value": "${SOKRATES_DATABASE_USER}"},
                    {"name": "SOKRATES_DATABASE_PASSWORD", "value": "${SOKRATES_DATABASE_PASSWORD}"},
                    {"name": "PLATO_DATA_MANAGEMENT_URL", "value": "${PLATO_DATA_MANAGEMENT_URL}"},
                    {"name": "PLATO_IDS_URL", "value": "${PLATO_IDS_URL}"},
                    {"name": "PLATO_DATA_PLANE_URL", "value": "${PLATO_DATA_PLANE_URL}"},
                    {"name": "PLATO_BACKEND_SERVICE_BACKEND_API_URL", "value": "http://backend:8081"},
                    {"name": "PLATO_DATABASE_URL", "value": "${PLATO_DATABASE_URL}"},
                    {"name": "PLATO_DATABASE_USER", "value": "${PLATO_DATABASE_USER}"},
                    {"name": "PLATO_DATABASE_PASSWORD", "value": "${PLATO_DATABASE_PASSWORD}"},
                    {"name": "EDC_AWS_ENDPOINT_OVERRIDE", "value": "${EDC_AWS_ENDPOINT_OVERRIDE}"},
                    {"name": "PLATO_AWS_SECRET_ACCESS_KEY", "value": "${PLATO_AWS_SECRET_ACCESS_KEY}"},
                    {"name": "PLATO_AWS_ACCESS_KEY_ID", "value": "${PLATO_AWS_ACCESS_KEY_ID}"},
                    {"name": "SOKRATES_AWS_SECRET_ACCESS_KEY", "value": "${SOKRATES_AWS_SECRET_ACCESS_KEY}"},
                    {"name": "SOKRATES_AWS_ACCESS_KEY_ID", "value": "${SOKRATES_AWS_ACCESS_KEY_ID}"}
                  ],
          EOF

          cat << EOF >> pod.json
                  "image": "openjdk:11-jdk-slim",
                  "name": "edc-tests-cucumber",
                  "volumeMounts": [
                    {
                      "mountPath": "/tractusx-edc",
                      "name": "tractusx-edc"
                    },
                    {
                      "mountPath": "/root/.m2/repository",
                      "name": "m2-repository"
                    }
                  ]
                }
              ],
              "dnsPolicy": "ClusterFirst",
              "restartPolicy": "Never",
              "volumes": [
                {
                  "hostPath": {
                    "path": "/srv/tractusx-edc"
                  },
                  "name": "tractusx-edc"
                },
                {
                  "hostPath": {
                    "path": "/srv/m2-repository"
                  },
                  "name": "m2-repository"
                }
              ]
            }
          }
          EOF

          kubectl run -i --image=openjdk:11-jdk-slim --restart=Never --rm edc-tests-cucumber --overrides="$(cat pod.json)"

      #################
      ### Tear Down ###
      #################
      - name: Destroy the kind cluster
        if: always()
        run: >-
          kind get clusters | xargs -n1 kind delete cluster --name
