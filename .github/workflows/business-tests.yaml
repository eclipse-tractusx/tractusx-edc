---
name: "Business Tests"

on:
  pull_request:
    paths-ignore:
      - 'docs/**'
      - '**/*.md'
    branches:
      - develop
      - release/**
      - main
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  business-test:
    runs-on: ubuntu-latest
    steps:
      ##############
      ### Set-Up ###
      ##############
      -
        name: Checkout
        uses: actions/checkout@v3.3.0
      -
        name: Set-Up JDK 11
        uses: actions/setup-java@v3.10.0
        with:
          java-version: '11'
          distribution: 'adopt'
          cache: 'gradle'
      -
        name: Cache ContainerD Image Layers
        uses: actions/cache@v3
        with:
          path: /var/lib/containerd/io.containerd.snapshotter.v1.overlayfs
          key: ${{ runner.os }}-io.containerd.snapshotter.v1.overlayfs
      -
        name: Set-Up Kubectl
        uses: azure/setup-kubectl@v3.2
      -
        name: Helm Set-Up
        uses: azure/setup-helm@v3.5
        with:
          version: v3.8.1
      -
        name: Create k8s Kind Cluster configuration (kind.config.yaml)
        run: |-
          export MAVEN_REPOSITORY=${{ github.workspace }}/.m2/repository
          cat << EOF > kind.config.yaml
          ---
          kind: Cluster
          apiVersion: kind.x-k8s.io/v1alpha4
          nodes:
          - role: control-plane
            extraMounts:
              - hostPath: ${PWD}
                containerPath: /srv/product-edc
              - hostPath: ${MAVEN_REPOSITORY}
                containerPath: /srv/m2-repository
              - hostPath: /var/lib/containerd/io.containerd.snapshotter.v1.overlayfs
                containerPath: /var/lib/containerd/io.containerd.snapshotter.v1.overlayfs
          EOF
      -
        name: Create k8s Kind Cluster
        uses: helm/kind-action@v1.5.0
        with:
          config: kind.config.yaml

      ##############################################
      ### Build and load recent images into KinD ###
      ##############################################
      -
        name: Build edc-controlplane-postgresql-hashicorp-vault
        run: |-
           ./gradlew :edc-controlplane:edc-controlplane-postgresql-hashicorp-vault:dockerize
        env:
          GITHUB_PACKAGE_USERNAME: ${{ github.actor }}
          GITHUB_PACKAGE_PASSWORD: ${{ secrets.GITHUB_TOKEN }}
      -
        name: Build edc-dataplane-hashicorp-vault
        run: |-
           ./gradlew :edc-dataplane:edc-dataplane-hashicorp-vault:dockerize
        env:
          GITHUB_PACKAGE_USERNAME: ${{ github.actor }}
          GITHUB_PACKAGE_PASSWORD: ${{ secrets.CXNG_GHCR_PAT }}
      -
        name: Load images into KinD
        run: |-
          docker tag edc-controlplane-postgresql-hashicorp-vault:latest edc-controlplane-postgresql-hashicorp-vault:business-test
          docker tag edc-dataplane-hashicorp-vault:latest edc-dataplane-hashicorp-vault:business-test
          kind get clusters | xargs -n1 kind load docker-image edc-controlplane-postgresql-hashicorp-vault:business-test edc-dataplane-hashicorp-vault:business-test --name

      ############################################
      ### Prepare And Install Test Environment ###
      ############################################
      -
        name: Define test environment variables
        run: |-
          # Define endpoints
          echo "SOKRATES_DATA_MANAGEMENT_API_AUTH_KEY=password" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_DATA_MANAGEMENT_URL=http://sokrates-controlplane:8081/data" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_IDS_URL=http://sokrates-controlplane:8084/api/v1/ids" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_DATA_PLANE_URL=http://sokrates-dataplane:8081/api/public/" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_DATABASE_URL=jdbc:postgresql://plato-postgresql:5432/edc" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_DATABASE_USER=user" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_DATABASE_PASSWORD=password" | tee -a ${GITHUB_ENV}
          echo "PLATO_DATA_MANAGEMENT_API_AUTH_KEY=password" | tee -a ${GITHUB_ENV}
          echo "PLATO_DATA_MANAGEMENT_URL=http://plato-controlplane:8081/data" | tee -a ${GITHUB_ENV}
          echo "PLATO_IDS_URL=http://plato-controlplane:8084/api/v1/ids" | tee -a ${GITHUB_ENV}
          echo "PLATO_DATA_PLANE_URL=http://plato-dataplane:8081/api/public/" | tee -a ${GITHUB_ENV}
          echo "PLATO_DATABASE_URL=jdbc:postgresql://plato-postgresql:5432/edc" | tee -a ${GITHUB_ENV}
          echo "PLATO_DATABASE_USER=user" | tee -a ${GITHUB_ENV}
          echo "PLATO_DATABASE_PASSWORD=password" | tee -a ${GITHUB_ENV}
          echo "EDC_AWS_ENDPOINT_OVERRIDE=http://minio:9000" | tee -a ${GITHUB_ENV}
          echo "PLATO_AWS_SECRET_ACCESS_KEY=platoqwerty123" | tee -a ${GITHUB_ENV}
          echo "PLATO_AWS_ACCESS_KEY_ID=platoqwerty123" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_AWS_SECRET_ACCESS_KEY=sokratesqwerty123" | tee -a ${GITHUB_ENV}
          echo "SOKRATES_AWS_ACCESS_KEY_ID=sokratesqwerty123" | tee -a ${GITHUB_ENV}
      -
        name: Install infrastructure components via Helm
        run: |-
          # Update helm dependencies
          helm dependency update edc-tests/src/main/resources/deployment/helm/supporting-infrastructure

          # Install the all-in-one supporting infrastructure environment (daps, vault, pgsql, minio)
          helm install infrastructure edc-tests/src/main/resources/deployment/helm/supporting-infrastructure \
            --wait-for-jobs --timeout=120s

          # GH pipelines constrained by cpu, so give helm some time to register all resources \w k8s
          sleep 5s

          # Wait for supporting infrastructure to become ready (control-/data-plane, backend service)
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=backend --timeout=120s || ( kubectl logs -l app.kubernetes.io/name=backend --tail 500 && exit 1 )
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=idsdaps --timeout=120s || ( kubectl logs -l app.kubernetes.io/name=idsdaps --tail 500 && exit 1 )
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=vault --timeout=120s || ( kubectl logs -l app.kubernetes.io/name=vault --tail 500 && exit 1 )
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=sokrates-postgresql --timeout=120s || ( kubectl logs -l app.kubernetes.io/name=sokrates-postgresql --tail 500 && exit 1 )
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=plato-postgresql --timeout=120s || ( kubectl logs -l app.kubernetes.io/name=plato-postgresql --tail 500 && exit 1 )
          kubectl wait --for=condition=ready pod -l app=minio --timeout=120s || ( kubectl logs -l app=minio --tail 500 && exit 1 )

          # Install Plato
          helm install plato charts/tractusx-connector  \
            --set fullnameOverride=plato \
            --set controlplane.service.type=NodePort \
            --set controlplane.endpoints.data.authKey=password \
            --set controlplane.image.tag=business-test \
            --set controlplane.image.pullPolicy=Never \
            --set controlplane.image.repository=docker.io/library/edc-controlplane-postgresql-hashicorp-vault \
            --set dataplane.image.tag=business-test \
            --set dataplane.image.pullPolicy=Never \
            --set dataplane.image.repository=docker.io/library/edc-dataplane-hashicorp-vault \
            --set controlplane.debug.enabled=true \
            --set controlplane.suspendOnStart=false \
            --set postgresql.enabled=true \
            --set postgresql.username=user \
            --set postgresql.password=password \
            --set postgresql.jdbcUrl=jdbc:postgresql://plato-postgresql:5432/edc \
            --set vault.hashicorp.enabled=true \
            --set vault.hashicorp.url=http://vault:8200 \
            --set vault.hashicorp.token=root \
            --set vault.secretNames.transferProxyTokenSignerPublicKey=plato/daps/my-plato-daps-crt \
            --set vault.secretNames.transferProxyTokenSignerPrivateKey=plato/daps/my-plato-daps-key \
            --set vault.secretNames.transferProxyTokenEncryptionAesKey=plato/data-encryption-aes-keys \
            --set vault.secretNames.dapsPrivateKey=plato/daps/my-plato-daps-key \
            --set vault.secretNames.dapsPublicKey=plato/daps/my-plato-daps-crt \
            --set daps.url=http://ids-daps:4567 \
            --set daps.clientId=99:83:A7:17:86:FF:98:93:CE:A0:DD:A1:F1:36:FA:F6:0F:75:0A:23:keyid:99:83:A7:17:86:FF:98:93:CE:A0:DD:A1:F1:36:FA:F6:0F:75:0A:23 \
            --set dataplane.aws.endpointOverride=http://minio:9000 \
            --set dataplane.aws.secretAccessKey=platoqwerty123 \
            --set dataplane.aws.accessKeyId=platoqwerty123 \
            --set backendService.httpProxyTokenReceiverUrl=http://backend:8080 \
            --wait-for-jobs --timeout=120s
          
          # Install Sokrates
          helm install sokrates charts/tractusx-connector  \
            --set fullnameOverride=sokrates \
            --set controlplane.service.type=NodePort \
            --set controlplane.endpoints.data.authKey=password \
            --set controlplane.image.tag=business-test \
            --set controlplane.image.pullPolicy=Never \
            --set controlplane.image.repository=docker.io/library/edc-controlplane-postgresql-hashicorp-vault \
            --set dataplane.image.tag=business-test \
            --set dataplane.image.pullPolicy=Never \
            --set dataplane.image.repository=docker.io/library/edc-dataplane-hashicorp-vault \
            --set controlplane.debug.enabled=true \
            --set controlplane.suspendOnStart=false \
            --set postgresql.enabled=true \
            --set postgresql.username=user \
            --set postgresql.password=password \
            --set postgresql.jdbcUrl=jdbc:postgresql://sokrates-postgresql:5432/edc \
            --set vault.hashicorp.enabled=true \
            --set vault.hashicorp.url=http://vault:8200 \
            --set vault.hashicorp.token=root \
            --set vault.secretNames.transferProxyTokenSignerPublicKey=sokrates/daps/my-sokrates-daps-crt \
            --set vault.secretNames.transferProxyTokenSignerPrivateKey=sokrates/daps/my-sokrates-daps-key \
            --set vault.secretNames.transferProxyTokenEncryptionAesKey=sokrates/data-encryption-aes-keys \
            --set vault.secretNames.dapsPrivateKey=sokrates/daps/my-sokrates-daps-key \
            --set vault.secretNames.dapsPublicKey=sokrates/daps/my-sokrates-daps-crt \
            --set daps.url=http://ids-daps:4567 \
            --set daps.clientId=E7:07:2D:74:56:66:31:F0:7B:10:EA:B6:03:06:4C:23:7F:ED:A6:65:keyid:E7:07:2D:74:56:66:31:F0:7B:10:EA:B6:03:06:4C:23:7F:ED:A6:65 \
            --set dataplane.aws.endpointOverride=http://minio:9000 \
            --set dataplane.aws.secretAccessKey=sokratesqwerty123 \
            --set dataplane.aws.accessKeyId=sokratesqwerty123 \
            --set backendService.httpProxyTokenReceiverUrl=http://backend:8080 \
            --wait-for-jobs --timeout=120s

          # GH pipelines constrained by cpu, so give helm some time to register all resources \w k8s
          sleep 5s

          # Wait for Control-/DataPlane and backend-service to become ready
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=sokrates-controlplane --timeout=600s || ( kubectl logs -l app.kubernetes.io/instance=sokrates-controlplane --tail 500 && exit 1 )
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=sokrates-dataplane --timeout=600s || ( kubectl logs -l app.kubernetes.io/instance=sokrates-dataplane --tail 500 && exit 1 )
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=plato-controlplane --timeout=600s || ( kubectl logs -l app.kubernetes.io/instance=plato-controlplane --tail 500 && exit 1 )
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=plato-dataplane --timeout=600s || ( kubectl logs -l app.kubernetes.io/instance=plato-dataplane --tail 500 && exit 1 )

      ##############################################
      ### Run Business Tests inside kind cluster ###
      ##############################################
      -
        name: Run Business Tests
        run: |-
          cat << EOF >> pod.json
          {
            "apiVersion": "v1",
            "kind": "Pod",
            "spec": {
              "containers": [
                {
                  "args": [
                    "-c",
                    "cd /product-edc && ./gradlew edc-tests:test -Dcucumber=true"
                  ],
                  "command": [
                    "/bin/sh"
                  ],
          EOF

          # Ugly hack to get env vars passed into the k8s-run - if '--overrides' defined '--env' is ignored :(
          cat << EOF >> pod.json
                  "env": [
                    {"name": "SOKRATES_DATA_MANAGEMENT_API_AUTH_KEY", "value": "${SOKRATES_DATA_MANAGEMENT_API_AUTH_KEY}"},
                    {"name": "PLATO_DATA_MANAGEMENT_API_AUTH_KEY", "value": "${PLATO_DATA_MANAGEMENT_API_AUTH_KEY}"},
                    {"name": "SOKRATES_DATA_MANAGEMENT_URL", "value": "${SOKRATES_DATA_MANAGEMENT_URL}"},
                    {"name": "SOKRATES_IDS_URL", "value": "${SOKRATES_IDS_URL}"},
                    {"name": "SOKRATES_DATA_PLANE_URL", "value": "${SOKRATES_DATA_PLANE_URL}"},
                    {"name": "SOKRATES_BACKEND_SERVICE_BACKEND_API_URL", "value": "http://backend:8081" },
                    {"name": "SOKRATES_DATABASE_URL", "value": "${SOKRATES_DATABASE_URL}"},
                    {"name": "SOKRATES_DATABASE_USER", "value": "${SOKRATES_DATABASE_USER}"},
                    {"name": "SOKRATES_DATABASE_PASSWORD", "value": "${SOKRATES_DATABASE_PASSWORD}"},
                    {"name": "PLATO_DATA_MANAGEMENT_URL", "value": "${PLATO_DATA_MANAGEMENT_URL}"},
                    {"name": "PLATO_IDS_URL", "value": "${PLATO_IDS_URL}"},
                    {"name": "PLATO_DATA_PLANE_URL", "value": "${PLATO_DATA_PLANE_URL}"},
                    {"name": "PLATO_BACKEND_SERVICE_BACKEND_API_URL", "value": "http://backend:8081"},
                    {"name": "PLATO_DATABASE_URL", "value": "${PLATO_DATABASE_URL}"},
                    {"name": "PLATO_DATABASE_USER", "value": "${PLATO_DATABASE_USER}"},
                    {"name": "PLATO_DATABASE_PASSWORD", "value": "${PLATO_DATABASE_PASSWORD}"},
                    {"name": "EDC_AWS_ENDPOINT_OVERRIDE", "value": "${EDC_AWS_ENDPOINT_OVERRIDE}"},
                    {"name": "PLATO_AWS_SECRET_ACCESS_KEY", "value": "${PLATO_AWS_SECRET_ACCESS_KEY}"},
                    {"name": "PLATO_AWS_ACCESS_KEY_ID", "value": "${PLATO_AWS_ACCESS_KEY_ID}"},
                    {"name": "SOKRATES_AWS_SECRET_ACCESS_KEY", "value": "${SOKRATES_AWS_SECRET_ACCESS_KEY}"},
                    {"name": "SOKRATES_AWS_ACCESS_KEY_ID", "value": "${SOKRATES_AWS_ACCESS_KEY_ID}"}
                  ],
          EOF

          cat << EOF >> pod.json
                  "image": "openjdk:11-jdk-slim",
                  "name": "edc-tests",
                  "volumeMounts": [
                    {
                      "mountPath": "/product-edc",
                      "name": "product-edc"
                    },
                    {
                      "mountPath": "/root/.m2/repository",
                      "name": "m2-repository"
                    }
                  ]
                }
              ],
              "dnsPolicy": "ClusterFirst",
              "restartPolicy": "Never",
              "volumes": [
                {
                  "hostPath": {
                    "path": "/srv/product-edc"
                  },
                  "name": "product-edc"
                },
                {
                  "hostPath": {
                    "path": "/srv/m2-repository"
                  },
                  "name": "m2-repository"
                }
              ]
            }
          }
          EOF

          kubectl run -i --image=openjdk:11-jdk-slim --restart=Never --rm edc-tests --overrides="$(cat pod.json)"

      #################
      ### Tear Down ###
      #################
      -
        name: Destroy the kind cluster
        if: always()
        run: >-
          kind get clusters | xargs -n1 kind delete cluster --name
